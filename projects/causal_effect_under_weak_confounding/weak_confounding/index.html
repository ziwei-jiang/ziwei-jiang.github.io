<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Approximate Causal Effect Identification under Weak Confounding | Ziwei's Site</title><meta name=keywords content="Causality"><meta name=description content=" 
Overview
In this project, we aimed to investigate the relationship between the influence of unobserved confounders and the deviation of spurious correlation from the true causal effect. This is similar to the concept of sensitivity analysis in the causal effect estimation. We utilized entropy as a measure to quantify the strength of the confounder and developed an algorithm to estimate bounds for the causal effect based on the observational distribution and the strength of confounders."><meta name=author content><link rel=canonical href=https://ziwei-jiang.github.io/projects/causal_effect_under_weak_confounding/weak_confounding/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.175f8a2522675f2652eb58ad47be19952cb91de9e66edc4b95bb19fff5546ef5.css integrity="sha256-F1+KJSJnXyZS61itR74ZlSy5HenmbtxLlbsZ//VUbvU=" rel="preload stylesheet" as=style><link rel=icon href=https://ziwei-jiang.github.io/img/abra_icon.png><link rel=icon type=image/png sizes=16x16 href=https://ziwei-jiang.github.io/img/abra_icon.png><link rel=icon type=image/png sizes=32x32 href=https://ziwei-jiang.github.io/img/abra_icon.png><link rel=apple-touch-icon href=https://ziwei-jiang.github.io/img/abra_icon.png><link rel=mask-icon href=https://ziwei-jiang.github.io/img/abra_icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://ziwei-jiang.github.io/projects/causal_effect_under_weak_confounding/weak_confounding/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.css integrity=sha384-bYdxxUwYipFNohQlHt0bjN/LCpueqWz13HufFEV1SUatKs1cm4L6fFgCi1jT643X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.js integrity=sha384-Qsn9KnoKISj6dI8g7p1HBlNpVx0I8p1SvlwOldgi3IorMle61nQy4zEahWYtljaz crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-H4P7KF2N8Z"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-H4P7KF2N8Z")}</script><meta property="og:url" content="https://ziwei-jiang.github.io/projects/causal_effect_under_weak_confounding/weak_confounding/"><meta property="og:site_name" content="Ziwei's Site"><meta property="og:title" content="Approximate Causal Effect Identification under Weak Confounding"><meta property="og:description" content=" Overview In this project, we aimed to investigate the relationship between the influence of unobserved confounders and the deviation of spurious correlation from the true causal effect. This is similar to the concept of sensitivity analysis in the causal effect estimation. We utilized entropy as a measure to quantify the strength of the confounder and developed an algorithm to estimate bounds for the causal effect based on the observational distribution and the strength of confounders."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="projects"><meta property="article:published_time" content="2023-07-18T11:30:03+00:00"><meta property="article:modified_time" content="2023-07-18T11:30:03+00:00"><meta property="article:tag" content="Causality"><meta property="og:image" content="https://ziwei-jiang.github.io/projects/causal_effect_under_weak_confounding/weak_confounding/projects/causal_effect_under_weak_confounding/imgs/cover.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://ziwei-jiang.github.io/projects/causal_effect_under_weak_confounding/weak_confounding/projects/causal_effect_under_weak_confounding/imgs/cover.png"><meta name=twitter:title content="Approximate Causal Effect Identification under Weak Confounding"><meta name=twitter:description content=" 
Overview
In this project, we aimed to investigate the relationship between the influence of unobserved confounders and the deviation of spurious correlation from the true causal effect. This is similar to the concept of sensitivity analysis in the causal effect estimation. We utilized entropy as a measure to quantify the strength of the confounder and developed an algorithm to estimate bounds for the causal effect based on the observational distribution and the strength of confounders."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Projects","item":"https://ziwei-jiang.github.io/projects/"},{"@type":"ListItem","position":2,"name":"Approximate Causal Effect Identification under Weak Confounding","item":"https://ziwei-jiang.github.io/projects/causal_effect_under_weak_confounding/weak_confounding/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Approximate Causal Effect Identification under Weak Confounding","name":"Approximate Causal Effect Identification under Weak Confounding","description":" Overview In this project, we aimed to investigate the relationship between the influence of unobserved confounders and the deviation of spurious correlation from the true causal effect. This is similar to the concept of sensitivity analysis in the causal effect estimation. We utilized entropy as a measure to quantify the strength of the confounder and developed an algorithm to estimate bounds for the causal effect based on the observational distribution and the strength of confounders.\n","keywords":["Causality"],"articleBody":" Overview In this project, we aimed to investigate the relationship between the influence of unobserved confounders and the deviation of spurious correlation from the true causal effect. This is similar to the concept of sensitivity analysis in the causal effect estimation. We utilized entropy as a measure to quantify the strength of the confounder and developed an algorithm to estimate bounds for the causal effect based on the observational distribution and the strength of confounders.\nCheckout Our Paper and Codes Approximate Causal Effect Identification under Weak Confounding[arXiv][code][video] Published in International Conference on Machine Learning (ICML), 2023\nQuantify the Confounder’s Strength Many studies use information theoretic quantities to measure the strength of edges in the causal graph, such as Entropic Causal Inference (Kocaoglu et al. 2017) and causal strength (Janzing et al. 2012). Inspired by these works, we consider the mutual information $I(X;Z)$ and $I(Y;Z)$ as the information between $X$ and $Y$ through the backdoor channel $Z$. Since $I(X;Z), I(Y;Z)\\leq H(Z)$, we use entropy to quantify the strength of confounders.\nWe want to draw connections between the strength of confounders and the deviation of causal effect due to the backdoor path. Formally, the problem is defined as:\n$$ \\text{Given }P(X, Y )\\text{ and } H(Z)\\leq θ,\\text{ finding the }\\min / \\max P(y | do(x)). $$\nThe Canonical Partition Method One can use the backdoor adjustment to estimate the causal effect if the confounder is observed. However, this method is not suitable for this problem. Due to the concavity of the entropy function, imposing the entropy constraint on the optimization problem results in a non-convex feasible set.\nThe Canonical Partition is a commonly used method for studying causal effects. It involves discrete variables $X$ and $Y$, and introduces variables $R_x$ and $R_y$ to represent the various possible mappings from $X$ to $Y$. Essentially, these response variables serve as parameters that capture the randomness of the functions responsible for mapping $X$ to $Y$.\nRepresent causal graph with canonical partition. When $X$ and $Y$ are binary variables, there are four possible mechanisms that depict how variable $Y$ responds to variable $X$, as illustrated in the figure below.\nCanonical partition for binary variables X, Y. Since $X$ is an exogenous variable given the observational distribution, we have $P(R_x) = P(X)$. As a result, we can use a total of 8 states to represent $P(R_x, R_y)$. We can represent the causal effect and observational distribution with the joint distribution of response variables $P(R_x, R_y)$.\nTable for canonical partition for binary variables X, Y. $$ P(y|do(x)) = \\sum_{i=0}^{1} \\sum_{j=0}^{1} P(R_y=i, R_x=j) $$ $$ P(x,y) = P(R_y=0, R_x=0)+ P(R_y=1, R_x=0) $$ $$ P(x,y) = P(R_y=2, R_x=0)+ P(R_y=3, R_x=0) $$\nFrom the above equation, Tian and Pearl (2000) showed the causal effect can be bounded as\n$$ P(x,y) \\leq P(y|do(x)) \\leq 1- P(x,y′). $$\nTo apply the entropy constraint, observe that the $R_x$ and $R_y$ are conditionally independent given the confounder $Z$.\nConditional independency in the canonical partition By the data processing inequality, the mutual information $I(R_x;R_y)$ is bounded by the entropy of $Z$. And since mutual information is a convex function of the conditional distributions $P(R_y|R_x)$, we can form the optimization problem as below.\nGiven $P(X,Y)$ for $ |X|=n, |Y|=m$ and entropy constraint $H(Z)\\leq \\theta$. The upper and lower bounds of causal effect $P(y_p|do(x_q))$ is given by\nHere $a_{ij}$ are the optimization parameters correspond to $P(R_y=i|R_x=j)$.\nSince the variable $R_y$ represents all possible mapping from $X$ to $Y$, we have the number of states $|R_y|=m^n$, and total number of parameters $|a|=nm^n$. The number of parameters grow exponentially with the number of states of $X$. So the optimization may become intractable for $X, Y$ in high dimensions.\nTo encounter this issue, we utilize a different parameterization of causal effect.\nThe Single World Intervention Graphs The Single World Intervention Graph (SWIG) is a graphical representation to link the counterfactual distribution and DAG introduced by Richardson and Robins (2013).\nRepresent causal graph with SWIG. Here $Y_x$ denotes the distribution of $Y$ after the intervention $do(X=x)$. By the graphical independency condition (also by the ignorability assumption), we have $Y_x$ and $X$ are conditionally independent given $Z$.\nConditional independency in the SWIG Again, by the data processing inequality, the mutual information $I(Y_x;X)$ is bounded by the entropy of confounder $H(Z)$. And we can formulate the optimization problem with the counterfactual distribution $P(Y_x, X)$ as below.\nGiven $P(X,Y)$ for $ |X|=n, |Y|=m$ and entropy constraint $H(Z)\\leq \\theta$. The upper and lower bounds of causal effect $P(y_p|do(x_q))$ is given by\nHere $b_{ij}$ are the optimization parameters correspond to $P(Y_x=i|X=j)$. We have $|Y_x|=m$ and $|b|=mn$.\nThe Entropy Threshold Now we want to determine the threshold of the entropy constraint such that its application yields tighter bounds. First, we look at the optimization parameters $b_{ij}$ in the conditional probability table.\nConditional probability table for the counterfactual distribution The causal effect achieves Tian-Pearl upper/lower bounds when the red row is maximized/minimized.\nFirst, we demonstrate that for binary variables $X$ and $Y$, maximizing the mutual information $I(Y_x;X)$ results in the achievement of bounds for a certain instance of causal effect. Assume, without loss of generality, $P(y|x) ≥ P(y′|x)$. The threshold of entropy constraint for obtaining tighter bounds is shown in the figure below.\nThe entropy threshold for binary X and Y. From the plot, we have the entropy threshold is maximized when $P(y|x)$ is closed to $0$ or $1$, and $P(x)$ is closed to $0.5$. In other words, we need larger mutual information $I(Y_x; X)$ to achieve maximum/minimum in those cases.\nThe brightness of the plot represents the gap between upper and lower bounds when the entropy constraint equals the threshold. So without the entropy constraint, the gap between upper and lower bounds is monotonically decreasing with $P(x)$.\nNext, we present several lemmas to determine the entropy threshold for non-binary $X$ or $Y$. In particular, we demonstrate that when either $X$ or $Y$ is binary, we can transform the optimization problem into the binary case by constructing a distribution $P(U,V)$. Consequently, we can extend the intuition from the binary $X,Y$ scenario to situations where either $X$ or $Y$ is non-binary.\nThe following figure shows the gap of our bounds vanishes as the entropy converge to zero. Each subplot represents a distribution of $P(X,Y)$. The green curves are the bounds given the entropy constraint and the red curves are the Tian-Pearl bounds.\nThe gap between upper/lower bounds for binary X and Y. Experiments We conducted experiments using both simulated and real-world data. For the simulated data, we generated distributions based on the given graph, incorporating small entropy confounders. Using the joint distribution $P(X, Y)$ and $H(Z)$, we computed the bounds of the causal effect. The figure below illustrates the average gap between bounds, grouped by entropy.\nAverage gaps in the simulated data The number of samples that yield tighter bounds is shown in the figures below.\nRegarding the real-world dataset, we selected a subset of variables and assumed that the confounders were not jointly observed; only the prior distributions were available. We demonstrated that our methods produced tight bounds even in the presence of small entropy confounders. These findings offer valuable information and guidance for decision-making processes.\nFor more details about the experiments, please refer to our paper.\nBibTeX @InProceedings{jiang2023approximate, title={Approximate Causal Effect Identification under Weak Confounding}, author={Jiang, Ziwei and Wei, Lai and Kocaoglu, Murat}, booktitle={International Conference on Machine Learning}, pages={15125--15143}, year={2023}, organization={PMLR} } ","wordCount":"1224","inLanguage":"en","image":"https://ziwei-jiang.github.io/projects/causal_effect_under_weak_confounding/weak_confounding/projects/causal_effect_under_weak_confounding/imgs/cover.png","datePublished":"2023-07-18T11:30:03Z","dateModified":"2023-07-18T11:30:03Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://ziwei-jiang.github.io/projects/causal_effect_under_weak_confounding/weak_confounding/"},"publisher":{"@type":"Organization","name":"Ziwei's Site","logo":{"@type":"ImageObject","url":"https://ziwei-jiang.github.io/img/abra_icon.png"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://ziwei-jiang.github.io/ accesskey=h title="Ziwei Jiang 姜子维 (Alt + H)"><img src=https://ziwei-jiang.github.io/img/abra_icon.png alt aria-label=logo height=35>Ziwei Jiang 姜子维</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://ziwei-jiang.github.io/about/ title=About><span>About</span></a></li><li><a href=https://ziwei-jiang.github.io/notes/ title=Notes><span>Notes</span></a></li><li><a href=https://ziwei-jiang.github.io/projects/ title=Projects><span>Projects</span></a></li><li><a href=https://ziwei-jiang.github.io/publications/ title=Publications><span>Publications</span></a></li><li><a href=https://ziwei-jiang.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Approximate Causal Effect Identification under Weak Confounding</h1><div class=post-meta><span title='2023-07-18 11:30:03 +0000 +0000'>July 18, 2023</span>&nbsp;·&nbsp;&nbsp;·&nbsp;<a href=/tags/causality> Causality</a></div></header><figure class=entry-cover1><img loading=lazy src=https://ziwei-jiang.github.io/projects/causal_effect_under_weak_confounding/imgs/cover.png alt><p></p></figure><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#overview aria-label=Overview>Overview</a></li><li><a href=#checkout-our-paper-and-codes aria-label="Checkout Our Paper and Codes">Checkout Our Paper and Codes</a></li><li><a href=#quantify-the-confounders-strength aria-label="Quantify the Confounder&rsquo;s Strength">Quantify the Confounder&rsquo;s Strength</a></li><li><a href=#the-canonical-partition-method aria-label="The Canonical Partition Method">The Canonical Partition Method</a></li><li><a href=#the-single-world-intervention-graphs aria-label="The Single World Intervention Graphs">The Single World Intervention Graphs</a></li><li><a href=#the-entropy-threshold aria-label="The Entropy Threshold">The Entropy Threshold</a></li><li><a href=#experiments aria-label=Experiments>Experiments</a></li><li><a href=#bibtex aria-label=BibTeX>BibTeX</a></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><p> </p><h1 id=overview>Overview<a hidden class=anchor aria-hidden=true href=#overview>#</a></h1><p>In this project, we aimed to investigate the relationship between the influence of unobserved confounders and the deviation of spurious correlation from the true causal effect. This is similar to the concept of sensitivity analysis in the causal effect estimation. We utilized entropy as a measure to quantify the strength of the confounder and developed an algorithm to estimate bounds for the causal effect based on the observational distribution and the strength of confounders.</p><h1 id=checkout-our-paper-and-codes>Checkout Our Paper and Codes<a hidden class=anchor aria-hidden=true href=#checkout-our-paper-and-codes>#</a></h1><p><a href=https://proceedings.mlr.press/v202/jiang23h><em>Approximate Causal Effect Identification under Weak Confounding</em></a>[<a href=https://arxiv.org/pdf/2306.13242.pdf>arXiv</a>][<a href=https://github.com/ziwei-jiang/Approximate-Causal-Effect-Identification-under-Weak-Confounding>code</a>][<a href="https://slideslive.com/39003243/approximate-causal-effect-identification-under-weak-confounding?ref=search-presentations-Approximate+Causal+Effect+Identification+under+Weak+Confounding">video</a>]
Published in International Conference on Machine Learning (ICML), 2023</p><h1 id=quantify-the-confounders-strength>Quantify the Confounder&rsquo;s Strength<a hidden class=anchor aria-hidden=true href=#quantify-the-confounders-strength>#</a></h1><p>Many studies use information theoretic quantities to measure the strength of edges in the causal graph, such as <a href=https://arxiv.org/abs/1611.04035>Entropic Causal Inference (Kocaoglu et al. 2017)</a> and <a href=https://arxiv.org/abs/1203.6502>causal strength (Janzing et al. 2012)</a>. Inspired by these works, we consider the mutual information $I(X;Z)$ and $I(Y;Z)$ as the information between $X$ and $Y$ through the backdoor channel $Z$. Since $I(X;Z), I(Y;Z)\leq H(Z)$, we use entropy to quantify the strength of confounders.</p><p>We want to draw connections between the strength of confounders and the deviation of causal effect due to the backdoor path. Formally, the problem is defined as:</p><p>$$ \text{Given }P(X, Y )\text{ and } H(Z)\leq θ,\text{ finding the }\min / \max P(y | do(x)). $$</p><h1 id=the-canonical-partition-method>The Canonical Partition Method<a hidden class=anchor aria-hidden=true href=#the-canonical-partition-method>#</a></h1><p>One can use the backdoor adjustment to estimate the causal effect if the confounder is observed. However, this method is not suitable for this problem. Due to the concavity of the entropy function, imposing the entropy constraint on the optimization problem results in a non-convex feasible set.</p><p>The <strong>Canonical Partition</strong> is a commonly used method for studying causal effects. It involves discrete variables $X$ and $Y$, and introduces variables $R_x$ and $R_y$ to represent the various possible mappings from $X$ to $Y$. Essentially, these response variables serve as parameters that capture the randomness of the functions responsible for mapping $X$ to $Y$.</p><figure class=align-center><img loading=lazy src=/projects/causal_effect_under_weak_confounding/imgs/cp_graph.png#center width=100%><figcaption>Represent causal graph with canonical partition.</figcaption></figure><p>When $X$ and $Y$ are binary variables, there are four possible mechanisms that depict how variable $Y$ responds to variable $X$, as illustrated in the figure below.</p><figure class=align-center><img loading=lazy src=/projects/causal_effect_under_weak_confounding/imgs/cp_binary.png#center width=50%><figcaption>Canonical partition for binary variables X, Y.</figcaption></figure><p>Since $X$ is an exogenous variable given the observational distribution, we have $P(R_x) = P(X)$. As a result, we can use a total of 8 states to represent $P(R_x, R_y)$.
We can represent the causal effect and observational distribution with the joint distribution of response variables $P(R_x, R_y)$.</p><figure class=align-center><img loading=lazy src=/projects/causal_effect_under_weak_confounding/imgs/cp_table.png#center width=55%><figcaption>Table for canonical partition for binary variables X, Y.</figcaption></figure><p>$$ P(y|do(x)) = \sum_{i=0}^{1} \sum_{j=0}^{1} P(R_y=i, R_x=j) $$
$$ P(x,y) = P(R_y=0, R_x=0)+ P(R_y=1, R_x=0) $$
$$ P(x,y) = P(R_y=2, R_x=0)+ P(R_y=3, R_x=0) $$</p><p>From the above equation, <a href=https://link.springer.com/article/10.1023/a:1018912507879>Tian and Pearl (2000)</a> showed the causal effect can be bounded as</p><p>$$ P(x,y) \leq P(y|do(x)) \leq 1- P(x,y′). $$</p><p>To apply the entropy constraint, observe that the $R_x$ and $R_y$ are conditionally independent given the confounder $Z$.</p><figure class=align-center><img loading=lazy src=/projects/causal_effect_under_weak_confounding/imgs/cp.png#center width=30%><figcaption>Conditional independency in the canonical partition</figcaption></figure><p>By the data processing inequality, the mutual information $I(R_x;R_y)$ is bounded by the entropy of $Z$. And since mutual information is a convex function of the conditional distributions $P(R_y|R_x)$, we can form the optimization problem as below.</p><p>Given $P(X,Y)$ for $ |X|=n, |Y|=m$ and entropy constraint $H(Z)\leq \theta$. The upper and lower bounds of causal effect $P(y_p|do(x_q))$ is given by</p><figure class=align-center><img loading=lazy src=/projects/causal_effect_under_weak_confounding/imgs/cp_bounds.png#center width=100%></figure><p>Here $a_{ij}$ are the optimization parameters correspond to $P(R_y=i|R_x=j)$.</p><p>Since the variable $R_y$ represents all possible mapping from $X$ to $Y$, we have the number of states $|R_y|=m^n$, and total number of parameters $|a|=nm^n$. The number of parameters grow exponentially with the number of states of $X$. So the optimization may become intractable for $X, Y$ in high dimensions.</p><p>To encounter this issue, we utilize a different parameterization of causal effect.</p><h1 id=the-single-world-intervention-graphs>The Single World Intervention Graphs<a hidden class=anchor aria-hidden=true href=#the-single-world-intervention-graphs>#</a></h1><p>The <strong>Single World Intervention Graph (SWIG)</strong> is a graphical representation to link the counterfactual distribution and DAG introduced by <a href="https://citeseerx.ist.psu.edu/document?repid=rep1&amp;type=pdf&amp;doi=89bd91b714f35759968555a87da06ce773a77f2f">Richardson and Robins (2013)</a>.</p><figure class=align-center><img loading=lazy src=/projects/causal_effect_under_weak_confounding/imgs/cf_graph.png#center width=100%><figcaption>Represent causal graph with SWIG.</figcaption></figure><p>Here $Y_x$ denotes the distribution of $Y$ after the intervention $do(X=x)$. By the graphical independency condition (also by the ignorability assumption), we have $Y_x$ and $X$ are conditionally independent given $Z$.</p><figure class=align-center><img loading=lazy src=/projects/causal_effect_under_weak_confounding/imgs/cf.png#center width=50%><figcaption>Conditional independency in the SWIG</figcaption></figure><p>Again, by the data processing inequality, the mutual information $I(Y_x;X)$ is bounded by the entropy of confounder $H(Z)$. And we can formulate the optimization problem with the counterfactual distribution $P(Y_x, X)$ as below.</p><p>Given $P(X,Y)$ for $ |X|=n, |Y|=m$ and entropy constraint $H(Z)\leq \theta$. The upper and lower bounds of causal effect $P(y_p|do(x_q))$ is given by</p><figure class=align-center><img loading=lazy src=/projects/causal_effect_under_weak_confounding/imgs/cf_bounds.png#center width=100%></figure><p>Here $b_{ij}$ are the optimization parameters correspond to $P(Y_x=i|X=j)$. We have $|Y_x|=m$ and $|b|=mn$.</p><h1 id=the-entropy-threshold>The Entropy Threshold<a hidden class=anchor aria-hidden=true href=#the-entropy-threshold>#</a></h1><p>Now we want to determine the threshold of the entropy constraint such that its application yields tighter bounds. First, we look at the optimization parameters $b_{ij}$ in the conditional probability table.</p><figure class=align-center><img loading=lazy src=/projects/causal_effect_under_weak_confounding/imgs/cf_table.png#center width=70%><figcaption>Conditional probability table for the counterfactual distribution</figcaption></figure><p>The causal effect achieves Tian-Pearl upper/lower bounds when the red row is maximized/minimized.</p><p>First, we demonstrate that for binary variables $X$ and $Y$, maximizing the mutual information $I(Y_x;X)$ results in the achievement of bounds for a certain instance of causal effect. Assume, without loss of generality, $P(y|x) ≥ P(y′|x)$. The threshold of entropy constraint for obtaining tighter bounds is shown in the figure below.</p><p><figure class=align-center><img loading=lazy src=/projects/causal_effect_under_weak_confounding/imgs/py_x_mi.png#center width=80%><figcaption>The entropy threshold for binary X and Y.</figcaption></figure>From the plot, we have the entropy threshold is maximized when $P(y|x)$ is closed to $0$ or $1$, and $P(x)$ is closed to $0.5$. In other words, we need larger mutual information $I(Y_x; X)$ to achieve maximum/minimum in those cases.</p><p>The brightness of the plot represents the gap between upper and lower bounds when the entropy constraint equals the threshold. So without the entropy constraint, the gap between upper and lower bounds is monotonically decreasing with $P(x)$.</p><p>Next, we present several lemmas to determine the entropy threshold for non-binary $X$ or $Y$. In particular, we demonstrate that when either $X$ or $Y$ is binary, we can transform the optimization problem into the binary case by constructing a distribution $P(U,V)$. Consequently, we can extend the intuition from the binary $X,Y$ scenario to situations where either $X$ or $Y$ is non-binary.</p><p>The following figure shows the gap of our bounds vanishes as the entropy converge to zero. Each subplot represents a distribution of $P(X,Y)$. The green curves are the bounds given the entropy constraint and the red curves are the Tian-Pearl bounds.</p><figure class=align-center><img loading=lazy src=/projects/causal_effect_under_weak_confounding/imgs/conf_interval_x2y2.png#center width=100%><figcaption>The gap between upper/lower bounds for binary X and Y.</figcaption></figure><h1 id=experiments>Experiments<a hidden class=anchor aria-hidden=true href=#experiments>#</a></h1><p>We conducted experiments using both simulated and real-world data. For the simulated data, we generated distributions based on the given graph, incorporating small entropy confounders. Using the joint distribution $P(X, Y)$ and $H(Z)$, we computed the bounds of the causal effect. The figure below illustrates the average gap between bounds, grouped by entropy.</p><figure class=align-center><img loading=lazy src=/projects/causal_effect_under_weak_confounding/imgs/gap_plot.png#center width=70%><figcaption>Average gaps in the simulated data</figcaption></figure><p>The number of samples that yield tighter bounds is shown in the figures below.</p><table><thead><tr><th style=text-align:center><img loading=lazy src=/projects/causal_effect_under_weak_confounding/imgs/bar_x2y2.png></th><th style=text-align:center><img loading=lazy src=/projects/causal_effect_under_weak_confounding/imgs/bar_x2y10.png></th><th style=text-align:center><img loading=lazy src=/projects/causal_effect_under_weak_confounding/imgs/bar_x10y2.png></th></tr></thead><tbody></tbody></table><p>Regarding the real-world dataset, we selected a subset of variables and assumed that the confounders were not jointly observed; only the prior distributions were available. We demonstrated that our methods produced tight bounds even in the presence of small entropy confounders. These findings offer valuable information and guidance for decision-making processes.</p><table><thead><tr><th style=text-align:center><img alt="ADULT dataset" loading=lazy src=/projects/causal_effect_under_weak_confounding/imgs/Adult.png></th><th style=text-align:center><img alt="INSURANCE dataset" loading=lazy src=/projects/causal_effect_under_weak_confounding/imgs/Insurance.png></th></tr></thead><tbody></tbody></table><p>For more details about the experiments, please refer to our paper.</p><h1 id=bibtex>BibTeX<a hidden class=anchor aria-hidden=true href=#bibtex>#</a></h1><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>@InProceedings{jiang2023approximate,
</span></span><span style=display:flex><span>  title={Approximate Causal Effect Identification under Weak Confounding},
</span></span><span style=display:flex><span>  author={Jiang, Ziwei and Wei, Lai and Kocaoglu, Murat},
</span></span><span style=display:flex><span>  booktitle={International Conference on Machine Learning},
</span></span><span style=display:flex><span>  pages={15125--15143},
</span></span><span style=display:flex><span>  year={2023},
</span></span><span style=display:flex><span>  organization={PMLR}
</span></span><span style=display:flex><span>}
</span></span></code></pre></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://ziwei-jiang.github.io/tags/causality/>Causality</a></li></ul><nav class=paginav><a class=prev href=https://ziwei-jiang.github.io/projects/conditional_common_entropy/conditional_common_entropy/><span class=title>« Prev</span><br><span>Conditional Common Entropy for Instrumental Variable Testing and Partial Identification</span>
</a><a class=next href=https://ziwei-jiang.github.io/projects/superquadric/superquadric/><span class=title>Next »</span><br><span>Extended Superquadric</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://ziwei-jiang.github.io/>Ziwei's Site</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>